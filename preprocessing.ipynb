{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification\n",
    "In this project, we will be classifying images of birds into 200 classes using cnn model. Our goal is to use less number of parameters(max 10M) and improve accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 03:16:20.593450: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-06 03:16:20.638120: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-06 03:16:20.638152: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-06 03:16:20.639349: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-06 03:16:20.646720: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-06 03:16:21.493542: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import keras, os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from efficientnet_pytorch import EfficientNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "# Define the path to the directory containing your JPEG images\n",
    "image_dir_test = \"CUB_200_2011/test\"\n",
    "image_dir_train = \"CUB_200_2011/train\"\n",
    "\n",
    "# Define the transformations to apply to the images\n",
    "# You can adjust these transformations based on your specific requirements\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(232, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),  # Convert PIL.Image to torch.Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "transform1 = transforms.Compose([\n",
    "    transforms.Resize(232, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.RandomHorizontalFlip(),  # Random horizontal flip\n",
    "    transforms.RandomRotation(10),      # Random rotation within -10 to 10 degrees\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),  # Convert PIL.Image to torch.Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Define a function to preprocess a single image\n",
    "def preprocess_image(image_path, transform, transform1):\n",
    "    image = Image.open(image_path).convert('RGB')  # Open the image using PIL\n",
    "    # print(image.shape)\n",
    "    image1 = transform(image)        # Apply the defined transformations\n",
    "    image2 = transform1(image)\n",
    "    return [image1, image2]\n",
    "\n",
    "# Iterate through each image in the directory, preprocess it, and store it in a list\n",
    "nameid = {}\n",
    "idlabel = {}\n",
    "with open('CUB_200_2011/images.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        value, key = line.split()\n",
    "        key = key.split('/')[1]\n",
    "        nameid[key] = value\n",
    "\n",
    "with open('CUB_200_2011/image_class_labels.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        key, value = line.split()\n",
    "        idlabel[key] = value\n",
    "\n",
    "y_train = []\n",
    "\n",
    "preprocessed_images = []\n",
    "for filename in os.listdir(image_dir_train):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        image_path = os.path.join(image_dir_train, filename)\n",
    "        preprocessed_image = preprocess_image(image_path, transform, transform1)\n",
    "        preprocessed_images.append(preprocessed_image[0])\n",
    "        preprocessed_images.append(preprocessed_image[1])\n",
    "        y_train.append(idlabel[nameid[filename]])\n",
    "        y_train.append(idlabel[nameid[filename]])\n",
    "\n",
    "# Concatenate the preprocessed images along the batch dimension to create a single tensor\n",
    "preprocessed_images_tensor = torch.stack(preprocessed_images)\n",
    "\n",
    "# Save the preprocessed images tensor to a file\n",
    "torch.save(preprocessed_images_tensor, \"preprocessed_images_train_aug.pt\")\n",
    "\n",
    "y_test = []\n",
    "preprocessed_images = []\n",
    "for filename in os.listdir(image_dir_test):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        image_path = os.path.join(image_dir_test, filename)\n",
    "        preprocessed_image = preprocess_image(image_path, transform, transform1)\n",
    "        preprocessed_images.append(preprocessed_image[0])\n",
    "        y_test.append(idlabel[nameid[filename]])\n",
    "\n",
    "# Concatenate the preprocessed images along the batch dimension to create a single tensor\n",
    "preprocessed_images_tensor = torch.stack(preprocessed_images)\n",
    "\n",
    "# Save the preprocessed images tensor to a file\n",
    "torch.save(preprocessed_images_tensor, \"preprocessed_images_test_aug.pt\")\n",
    "\n",
    "import pickle\n",
    "with open(\"test_label_aug.pkl\", \"wb\") as file:\n",
    "    pickle.dump(y_test, file)\n",
    "with open(\"train_label_aug.pkl\", \"wb\") as file:\n",
    "    pickle.dump(y_train, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1776869/4071059991.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_label_aug.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_label_aug.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"test_label_aug.pkl\", \"wb\") as file:\n",
    "    pickle.dump(y_test, file)\n",
    "with open(\"train_label_aug.pkl\", \"wb\") as file:\n",
    "    pickle.dump(y_train, file)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loaded pretrained weights for efficientnet-b2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load pretrained EfficientNet B2 model\n",
    "model = EfficientNet.from_pretrained('efficientnet-b2')\n",
    "model.to(device)\n",
    "\n",
    "# Define your custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_file, labels):\n",
    "        self.data = torch.load(data_file)  # Load data from .pt file\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get data and label for the given index\n",
    "        data_item = self.data[idx].to(device)\n",
    "        label = self.labels[idx].to(device)\n",
    "        return data_item, label\n",
    "\n",
    "# Load the pickle file into a list\n",
    "with open(\"list.pkl\", \"rb\") as file:\n",
    "    y_train_old = pickle.load(file)\n",
    "\n",
    "y_train = torch.tensor(y_train_old, dtype=torch.long).to(device)\n",
    "\n",
    "dataset = CustomDataset('preprocessed_images_train.pt', y_train)\n",
    "\n",
    "batch_size = 32\n",
    "shuffle = True  # You can set this to True for training\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Train the model or load your own data for fine-tuning\n",
    "# Example:\n",
    "training_loss = []\n",
    "print(\"Training...\")\n",
    "for inputs, labels in tqdm(dataloader, desc=\"Training\"):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    training_loss.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(\"Training completed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
